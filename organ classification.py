# -*- coding: utf-8 -*-
"""Mini Project-Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yh5Uu-Sj3ZMQsMiTtURNLN0GugOLRqa3
"""

pip install medmnist

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from torchvision import models
from tqdm import tqdm
from collections import defaultdict
import medmnist
from medmnist import INFO
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns

# Set random seed for reproducibility
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)

set_seed()

# Check device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Define transform for the dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# Load OrganMNIST dataset
data_flag = 'organcmnist'
info = INFO[data_flag]
DataClass = getattr(medmnist, info['python_class'])

train_dataset = DataClass(split='train', transform=transform, download=True)
val_dataset = DataClass(split='val', transform=transform, download=True)
test_dataset = DataClass(split='test', transform=transform, download=True)

print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")
print(f"Test samples: {len(test_dataset)}")

train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)

classes = INFO[data_flag]['label']
print(f"Classes: {classes}")

# Mapping organ label to cohort label
COHORT_MAP = {0: 2, 1: 1, 2: 1, 3: 0, 4: 2, 5: 2, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}

def organ_to_cohort(labels):
    return torch.tensor([COHORT_MAP[label.item()] for label in labels])

cohort_titles = {
    0: "Central Organs",
    1: "Limbs",
    2: "Urinary Organs"
}

organ_titles = {
    0: "Bladder",
    1: "Femur-Left",
    2: "Femur-Right",
    3: "Heart",
    4: "Kidney-Left",
    5: "Kidney-Right",
    6: "Liver",
    7: "Lung-Left",
    8: "Lung-Right",
    9: "Pancreas",
    10: "Spleen"
}

cohort_info = {}

for label, cohort in COHORT_MAP.items():
    organ_name = organ_titles[label]
    cohort_name = cohort_titles[cohort]

    if cohort_name not in cohort_info:
        cohort_info[cohort_name] = []
    cohort_info[cohort_name].append(organ_name)

# Display
for cohort, organs in cohort_info.items():
    print(f"Cohort: {cohort}")
    for organ in organs:
        print(f"  - {organ}")
    print()

# Baseline ResNet Model
class OrganResNet(nn.Module):
    def __init__(self, num_classes=11):
        super(OrganResNet, self).__init__()
        self.model = models.resnet18(weights=None)
        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=0, bias=False)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

# CohortResNet Model
class CohortResNet(nn.Module):
    def __init__(self, num_classes=11, num_cohorts=3):
        super(CohortResNet, self).__init__()
        self.base = models.resnet18(weights=None)
        self.base.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=0, bias=False)
        feature_dim = self.base.fc.in_features
        self.base.fc = nn.Identity()
        self.organ_head = nn.Linear(feature_dim, num_classes)
        self.cohort_head = nn.Linear(feature_dim, num_cohorts)

    def forward(self, x):
        features = self.base(x)
        return self.organ_head(features), self.cohort_head(features)

# Training and evaluation functions
def train_baseline(model, train_loader, val_loader, epochs=10):
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    train_losses = []
    val_accuracies = []

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for images, labels in tqdm(train_loader, desc=f"[Baseline] Epoch {epoch+1}/{epochs}"):
            images, labels = images.to(device), labels.squeeze().long().to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_train_loss = total_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        # Validation accuracy
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.squeeze().long().to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_acc = 100 * correct / total
        val_accuracies.append(val_acc)
        print(f"[Baseline] Epoch {epoch+1}: Train Loss {avg_train_loss:.4f}, Val Acc {val_acc:.2f}%")

    return train_losses, val_accuracies

def train_cohort(model, train_loader, val_loader, epochs=10, alpha=0.5, beta=0.5):
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion_class = nn.CrossEntropyLoss()
    criterion_cohort = nn.CrossEntropyLoss()
    train_loss_list = []
    organ_acc_list = []
    cohort_acc_list = []

    for epoch in range(epochs):
        model.train()
        running_loss = 0
        for images, labels in tqdm(train_loader, desc=f"[Cohort] Epoch {epoch+1}/{epochs}"):
            images, labels = images.to(device), labels.squeeze().long().to(device)
            cohort_labels = organ_to_cohort(labels).to(device)

            optimizer.zero_grad()
            organ_logits, cohort_logits = model(images)
            loss_class = criterion_class(organ_logits, labels)
            loss_cohort = criterion_cohort(cohort_logits, cohort_labels)
            total_loss = alpha * loss_class + beta * loss_cohort
            total_loss.backward()
            optimizer.step()
            running_loss += total_loss.item()

        avg_train_loss = running_loss / len(train_loader)
        train_loss_list.append(avg_train_loss)

        correct_organ = 0
        correct_cohort = 0
        total = 0

        model.eval()
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.squeeze().long().to(device)
                cohort_labels = organ_to_cohort(labels).to(device)
                organ_logits, cohort_logits = model(images)
                _, organ_preds = torch.max(organ_logits, 1)
                _, cohort_preds = torch.max(cohort_logits, 1)
                total += labels.size(0)
                correct_organ += (organ_preds == labels).sum().item()
                correct_cohort += (cohort_preds == cohort_labels).sum().item()

        organ_acc = 100 * correct_organ / total
        cohort_acc = 100 * correct_cohort / total
        organ_acc_list.append(organ_acc)
        cohort_acc_list.append(cohort_acc)

        print(f"[Cohort] Epoch {epoch+1}: Train Loss {avg_train_loss:.4f}, Organ Acc {organ_acc:.2f}%, Cohort Acc {cohort_acc:.2f}%")

    return train_loss_list, organ_acc_list, cohort_acc_list

# Evaluation function with confusion matrix and test Accuracies
def evaluate_with_metrics(model, loader, is_cohort=False):
    model.eval()
    y_true, y_pred = [], []
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.squeeze().long().to(device)
            if is_cohort:
                cohort_labels = organ_to_cohort(labels).to(device)
                _, cohort_logits = model(images)
                _, preds = torch.max(cohort_logits, 1)
                y_true.extend(cohort_labels.cpu().numpy())
            else:
                outputs = model(images) if not isinstance(model, CohortResNet) else model(images)[0]
                _, preds = torch.max(outputs, 1)
                y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    y_true, y_pred = np.array(y_true), np.array(y_pred)
    test_acc = np.mean(y_true == y_pred)
    print(f"Test Accuracy: {test_acc * 100:.2f}%")
    print(classification_report(y_true, y_pred))
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues' if not is_cohort else 'Greens')
    plt.title("Confusion Matrix" + (" - Cohort" if is_cohort else " - Organ"))
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# Run experiments
baseline_model = OrganResNet()
cohort_model = CohortResNet()

baseline_train_losses, baseline_val_accuracies = train_baseline(baseline_model, train_loader, val_loader)
cohort_train_losses, cohort_organ_accuracies, cohort_cohort_accuracies = train_cohort(cohort_model, train_loader, val_loader)

# 12. Plot accuracy comparison
plt.figure(figsize=(12, 5))

plt.plot(baseline_val_accuracies, label='Baseline Organ Accuracy')
plt.plot(cohort_organ_accuracies, label='Cohort Organ Accuracy')
plt.plot(cohort_cohort_accuracies, label='Cohort Prediction Accuracy', color='green')

plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy Comparison')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Final evaluations
print("\nBaseline Model Final Evaluation:")
evaluate_with_metrics(baseline_model, test_loader)

print("\nCohort Model Organ Evaluation:")
evaluate_with_metrics(cohort_model, test_loader)

print("\nCohort Model Cohort Evaluation:")
evaluate_with_metrics(cohort_model, test_loader, is_cohort=True)

def visualize_predictions(model, loader, num_samples=10, model_type="Baseline"):
    model.eval()
    fig, axes = plt.subplots(2, num_samples, figsize=(20, 6))  # 2 rows for image and labels
    fig.suptitle(f"{model_type} Model Predictions", fontsize=16)

    with torch.no_grad():
        images, labels = next(iter(loader))  # Get the first batch
        images, labels = images.to(device), labels.squeeze().long().to(device)

        if model_type == "Cohort":
            organ_outputs, cohort_outputs = model(images)
            _, organ_preds = torch.max(organ_outputs, 1)
            _, cohort_preds = torch.max(cohort_outputs, 1)
        else:
            outputs = model(images)
            _, preds = torch.max(outputs, 1)

        for i in range(num_samples):
            # Display image
            image = images[i].cpu().numpy().squeeze()  # Remove channel dimension
            axes[0, i].imshow(image, cmap='gray')
            axes[0, i].axis('off')

            # Display true and predicted labels
            # Access elements in the classes list directly using indices
            true_label_index = labels[i].item()

            # Check if the index is within the bounds of classes before accessing it.
            # Use organ_titles instead of classes for label lookup
            true_label = organ_titles.get(true_label_index, f"Unknown ({true_label_index})")

            if model_type == "Cohort":
                pred_label_index = organ_preds[i].item()
                # Check if the index is within the bounds of classes before accessing it.
                # Use organ_titles instead of classes for label lookup
                pred_label = organ_titles.get(pred_label_index, f"Unknown ({pred_label_index})")
                cohort_label_index = cohort_preds[i].item()
                cohort_label = cohort_titles.get(cohort_label_index, f"Unknown ({cohort_label_index})")

                axes[1, i].text(0.5, 0.5, f"True: {true_label}\nPred: {pred_label}\nCohort: {cohort_label}",
                               ha='center', va='center', fontsize=10)
            else:
                pred_label_index = preds[i].item()
                # Check if the index is within the bounds of classes before accessing it.
                # Use organ_titles instead of classes for label lookup
                pred_label = organ_titles.get(pred_label_index, f"Unknown ({pred_label_index})")
                axes[1, i].text(0.5, 0.5, f"True: {true_label}\nPred: {pred_label}",
                               ha='center', va='center', fontsize=10)
            axes[1, i].axis('off')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for title
    plt.show()

# Call the function to visualize predictions
visualize_predictions(baseline_model, test_loader, model_type="Baseline")
visualize_predictions(cohort_model, test_loader, model_type="Cohort")

torch.save(baseline_model.state_dict(), "baseline_model.pth")

from google.colab import files
files.download("baseline_model.pth")

!pip install gradio

model = OrganResNet()
model.load_state_dict(torch.load("baseline_model.pth", map_location='cpu'))
model.eval()

from PIL import Image
import torch
from torchvision import transforms
import gradio as gr

# same organ_titles as before
organ_titles = {
    0: "Bladder", 1: "Femur-Left", 2: "Femur-Right", 3: "Heart",
    4: "Kidney-Left", 5: "Kidney-Right", 6: "Liver", 7: "Lung-Left",
    8: "Lung-Right", 9: "Pancreas", 10: "Spleen"
}

transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

def predict(image):
    image = image.convert("L")  # grayscale
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(image)
        _, pred = torch.max(output, 1)
    return organ_titles[pred.item()]

interface = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Organ Classifier",
    description="Upload an organ image from MedMNIST, and this model will predict the organ class. “Use 28x28 grayscale PNG images from MedMNIST. You can download samples from: https://medmnist.com/”"
)

interface.launch(share=True)

